ext {
    versions = [:]
    libs = [:]
}
versions += [
        scala: "2.10",
        spark: "1.3.1"
]
libs += [
        avro: "org.apache.avro:avro:1.7.7",
        /*avroTools: "org.apache.avro:avro-tools:1.7.7",
        commonsLang: "org.apache.commons:commons-lang3:3.4",
        commonsIO: "commons-io:commons-io:2.4",
        curatorTest: "org.apache.curator:curator-test:2.8.0",
        guava: "com.google.guava:guava:18.0",
        hadoopClient: "org.apache.hadoop:hadoop-client:2.0.0-cdh4.6.0",
        jCommander: "com.beust:jcommander:1.30",*/
        gson: "com.google.code.gson:gson:2.3.1",
        fastjson:'com.alibaba:fastjson:1.2.39',
        jodaTime: "joda-time:joda-time:2.3",
        jodaConvert: "org.joda:joda-convert:1.8.1",
        kafkaTest: "org.apache.kafka:kafka_2.10:0.8.2.1:test",
        httpClient: "org.apache.httpcomponents:httpclient:4.2.5",
        json4sJackson: "org.json4s:json4s-jackson_$versions.scala:3.2.+",
        /*openCsv: "net.sf.opencsv:opencsv:2.3",
        parquetAvro: "com.twitter:parquet-avro:1.6.0",*/
        scala: "org.scala-lang:scala-library:$versions.scala.4",
        scalaRef: "org.scala-lang:scala-reflect:$versions.scala.4",
        log4j: "log4j:log4j:1.2.17",
        slf4jLog4j: "org.slf4j:slf4j-log4j12:1.7.12",
        slf4jApi: "org.slf4j:slf4j-api:1.7.12",
        lombok: "org.projectlombok:lombok:1.16.18",
        //scalaWebSockets: "eu.piotrbuda:scalawebsocket_2.10:0.1.1",
        spark: "org.apache.spark:spark-core_$versions.scala:$versions.spark",
        /*sparkGraphX: "org.apache.spark:spark-graphx_$versions.scala:$versions.spark",
        sparkMlLib: "org.apache.spark:spark-mllib_$versions.scala:$versions.spark",*/
        sparkStreaming: "org.apache.spark:spark-streaming_$versions.scala:$versions.spark",
        //sparkStreamingFlume: "org.apache.spark:spark-streaming-flume_$versions.scala:$versions.spark",
        sparkStreamingKafka: "org.apache.spark:spark-streaming-kafka_$versions.scala:$versions.spark",
        //sparkStreamingTwitter: "org.apache.spark:spark-streaming-twitter_$versions.scala:$versions.spark",
        //sparkStreamingZeroMQ: "org.apache.spark:spark-streaming-zeromq_$versions.scala:$versions.spark",
        //testNG: "org.testng:testng:6.9.4",
        kafka: "org.apache.kafka:kafka_2.10:0.8.2.1",
        redisClient: "redis.clients:jedis:2.8.1",
        elasticsearch: 'org.elasticsearch.client:transport:5.5.2',
        netty_all:"io.netty:netty-all:4.1.13.Final",
        scopt: "com.github.scopt:scopt_2.10:2.1.0",
        protobuf: "com.google.protobuf:protobuf-java:2.5.0",
        typesafeConfig: "com.typesafe:config:1.0.0",
        scalaTest: "org.scalatest:scalatest_$versions.scala:+",
        lucene_core: "org.apache.lucene:lucene-core:6.5.0",
        lucene_queryparser: "org.apache.lucene:lucene-queryparser:6.5.0",
        lucene_analyzers_common: "org.apache.lucene:lucene-analyzers-common:6.5.0",
        tensorflow: "org.tensorflow:tensorflow:1.4.0",
        dl4j: "org.deeplearning4j:deeplearning4j-core:1.0.0-beta2",
        nd4j_native: "org.nd4j:nd4j-native-platform:1.0.0-beta2",
        jfree: "jfree:jfreechart:1.0.13",
        disruptor: "com.lmax:disruptor:3.4.2"
]